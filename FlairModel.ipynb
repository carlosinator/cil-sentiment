{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmjqjlr8epZTKk7AkhZeOv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dPLASz7TUsHQ"},"outputs":[],"source":["from google.colab import auth\n","\n","auth.authenticate_user()"]},{"cell_type":"code","source":["%%bash\n","pip3 install flair"],"metadata":{"id":"aFB8pdY8U5LV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","from sklearn import metrics\n","from flair.data import Corpus\n","from flair.datasets import CSVClassificationCorpus\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings,\\\n","  DocumentLSTMEmbeddings, DocumentPoolEmbeddings, TransformerDocumentEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer\n","import tensorflow as tf"],"metadata":{"id":"i_jZfUv4U8Uc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gsutil cp \"gs://cil_2023/train_pos_preprocessed.txt\" .\n","!gsutil cp \"gs://cil_2023/train_neg_preprocessed.txt\" .\n","\n","filename_train_pos = \"train_pos_preprocessed.txt\"\n","filename_train_neg = \"train_neg_preprocessed.txt\""],"metadata":{"id":"TqBJSs3QU_lD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_type='sentiment'\n","\n","# read dataset\n","dataset_pos_pd = pd.read_fwf(filename_train_pos, sep='\\n', header=None, names=['text'])\n","dataset_neg_pd = pd.read_fwf(filename_train_neg, sep='\\n', header=None, names=['text'])\n","dataset_pos_pd[label_type] = \"POSITIVE\"\n","dataset_neg_pd[label_type] = \"NEGATIVE\"\n","dataset_pd = pd.concat([dataset_pos_pd, dataset_neg_pd])\n","\n","# shuffle\n","dataset_pd = dataset_pd.sample(frac=1, random_state=0).reset_index(drop=True)[:1000]\n","\n","# train-test-val split\n","N = len(dataset_pd)\n","train_size = int(0.8 * N)\n","val_size = int(0.1 * N)\n","test_size = N - train_size - val_size\n","dataset_train = dataset_pd[:train_size]\n","dataset_val = dataset_pd[train_size:(train_size + val_size)]\n","dataset_test = dataset_pd[(train_size + val_size):]\n","\n","# load into corpus\n","dataset_train.to_csv('train.csv', sep='\\t')\n","dataset_val.to_csv('dev.csv', sep='\\t')\n","dataset_test.to_csv('test.csv', sep='\\t')"],"metadata":{"id":"XnBwGl-ZVCdd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus: Corpus = CSVClassificationCorpus(\"./\", {1: 'text', 2: 'label'},\n","                                         skip_header=True,\n","                                         label_type=label_type,\n","                                         delimiter='\\t',\n","                                         train_file='train.csv',\n","                                         dev_file='dev.csv',\n","                                         test_file='test.csv',\n","                                         )\n","label_dict = corpus.make_label_dictionary(label_type=label_type)"],"metadata":{"id":"M6U6e2UtVL3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier = TextClassifier.load('en-sentiment')\n","trainer = ModelTrainer(classifier, corpus)\n","\n","trainer.fine_tune('./', max_epochs=1, main_evaluation_metric=(\"macro avg\", \"f1-score\"))"],"metadata":{"id":"_wvDeF-cVP8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","word_embeddings = [FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n","\n","document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n","\n","classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type=label_type)\n","\n","trainer = ModelTrainer(classifier, corpus)\n","\n","trainer.train('./', max_epochs=5)\n","\"\"\"\n"],"metadata":{"id":"N8Ql8TmDVXKI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","from flair.data import Sentence\n","from sklearn.metrics import accuracy_score\n","\n","sentences = [Sentence(t) for t in dataset_train['text'][:1000]]\n","classifier.predict(sentences)\n","predictions = [s.get_label().value for s in sentences]\n","accuracy_score(predictions, dataset_train['sentiment'][:1000])\n","\"\"\"\n"],"metadata":{"id":"IJNjDlzmVdWa"},"execution_count":null,"outputs":[]}]}